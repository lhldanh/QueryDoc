# ğŸ“„ QueryDoc â€” Hybrid PDF RAG with Evidence Viewer

**QueryDoc** is a document question-answering system built on **Hybrid Retrieval (BM25 + Vector Search)** that allows users to chat with PDF documents while **verifying answers directly on the original pages with precise highlights**.

> **Core Idea:** Donâ€™t just answer questions â€” show the evidence.

---

## ğŸ“º Demo Video
*(Click the badge below to watch QueryDoc in action)*

[![QueryDoc Demo](https://img.shields.io/badge/YOUTUBE-WATCH_DEMO-red?style=for-the-badge&logo=youtube)](https://youtu.be/zgT5YYwKriM)

---

## âœ¨ Key Features
- ğŸ” **Hybrid Retrieval**: BM25 + Vector Search + RRF
- ğŸ“ **Citations with exact page references**
- ğŸ–ï¸ **Evidence Viewer** with bounding-box highlights

---

## ğŸ–¥ï¸ Demo UI

| Chat Interface | Evidence Viewer |
|---------------|-----------------|
| ![](images/demo.png) | ![](images/evidence.png) |

*Chat with documents on the left, inspect evidence on a separate page with precise highlights.*

---

## ğŸ—ºï¸ System Pipeline

![QueryDoc Pipeline](images\pipeline.svg)

---

## ğŸš€ Quickstart

### 1ï¸. Clone the repository
```bash
git clone https://github.com/lhldanh/querydoc.git
cd querydoc
```
### 2. Activate your environment
```bash
# Windows
.\rag_env\Scripts\activate

# Linux / macOS
source rag_env/bin/activate
```
### 3. Install dependencies
```bash
pip install -r requirements.txt
```
Requirements: Ollama running locally with a supported LLM (e.g. `qwen2.5`, `llama3`).

### 4. Run the app
```bash
streamlit run src/app.py
```

---

## ğŸ§  Architecture

- **Ingestion:** PDF â†’ passages + bounding boxes

- **Indexing:**
    - BM25 for keyword search
    - Vector embeddings for semantic search

- **Retrieval:** Hybrid Retrieval with Reciprocal Rank Fusion (RRF)

- **Generation:** LLM answers strictly based on retrieved passages

- **Verification:** Evidence Viewer highlights exact source text

---

## ğŸ“š License
MIT License
